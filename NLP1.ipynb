{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4457a587-e00a-4acc-8861-a6e775212fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp310-cp310-macosx_10_12_x86_64.whl.metadata (52 kB)\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.5-cp310-cp310-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from matplotlib) (12.1.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.8-cp310-cp310-macosx_10_12_x86_64.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wordcloud-1.9.5-cp310-cp310-macosx_10_9_x86_64.whl (169 kB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl (268 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp310-cp310-macosx_10_9_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp310-cp310-macosx_10_9_x86_64.whl (66 kB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, wordcloud\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [wordcloud]━━━━━━━━\u001b[0m \u001b[32m5/7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pyparsing-3.3.1 wordcloud-1.9.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892abd6a-1eab-4cf7-86e5-41819d55ec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Using cached xlrd-2.0.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Using cached xlrd-2.0.2-py2.py3-none-any.whl (96 kB)\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da574812-4405-40b3-81d5-8348728f1db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.3.3-cp310-cp310-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, pandas\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pandas]━━━━\u001b[0m \u001b[32m1/2\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a44c6e-bb9e-4a45-b769-22fe5c3479b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-macosx_10_9_x86_64.whl (290 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [nltk]━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [nltk]]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed click-8.3.1 joblib-1.5.3 nltk-3.9.2 regex-2025.11.3 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a26dff-ee51-4041-a3bd-ea95a380d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re #정규 표현식 특수문자를 제거하는 텍스트 클리닝\n",
    "from functools import reduce #리스트 안의 리스트를 하나로 합치는 등 반복적인 연산을 누적해서 수행하는 \n",
    "import platform\n",
    "import os\n",
    "#nltk: 영어전용NLP도구 모음\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Okt: 한국어 문장에서 명사, 동사, 형용사 등을 분리 해주는\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import STOPWORDS, WordCloud\n",
    "import matplotlib.font_manager as fm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719ba750-feb8-446d-9cc9-a653724fcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_txt = \"\"\"\n",
    "[앵커]\n",
    "지난주 4000선 아래로 떨어졌던 코스피가 상승 출발해 장 초반 4000선을 회복했습니다.\n",
    "\n",
    "원-달러 환율은 1,450원을 넘어서 불안한 모습을 보이고 있습니다.\n",
    "\n",
    "취재기자를 연결해 금융시장 상황 알아보겠습니다.\n",
    "\n",
    "류환홍 기자, 코스피가 현재는 얼마나 올라왔습니까?\n",
    "\n",
    "[기자]\n",
    "현재는 4060선에 올라와 있습니다.\n",
    "\n",
    "코스피는 1% 오른 3,991로 출발했는데 개장 1분 후 4000선을 회복했습니다.\n",
    "\n",
    "이후 상승폭이 2% 넘게 커지며 4060선도 넘었습니다.\n",
    "\n",
    "외국인과 기관이 동반 순매수를 보이며 지수가 상승했습니다.\n",
    "\n",
    "외국인 순매수는 6일 만입니다.\n",
    "\n",
    "시가총액 상위 종목 거의 대부분 상승 중입니다.\n",
    "\n",
    "삼성전자는 2% 넘게 올라 장중에 '10만 전자'를 회복했고 SK하이닉스는 5% 넘게 올라 장중에 '61만 닉스'를 회복했습니다.\n",
    "\n",
    "하나와 KB, iM 금융지주 등 은행주는 4% 이상 급등하는 등 강세를 보이고 있습니다.\n",
    "\n",
    "코스닥도 0.6% 상승 출발했지만 하락과 상승을 반복하며 혼조세를 보이고 있습니다.\n",
    "\n",
    "개인이 순매수이지만 외국인과 기관은 순매도입니다.\n",
    "\n",
    "지난주 금요일 뉴욕 증시가 혼조세로 마감했고 원-달러 환율이 오르고 있어서 하락 출발할 것이란 전망이 있었는데 현재까지 코스피는 선방하고 있습니다.\n",
    "\n",
    "시장에선 미국 행정부의 셧다운 해제가 임박했다는 소식과 우리 정부의 배당소득 분리과세 완화 방침에 코스피가 반등한 것으로 보고 있습니다.\n",
    "\n",
    "원-달러 환율은 1,450원을 넘었습니다.\n",
    "\n",
    "서울 외환시장에서 원-달러 환율은 1,457원으로 출발했고 현재도 1,450원대에 올라와 있습니다.\n",
    "\n",
    "원-달러 환율이 지난 7일 7개월 만에 처음 1,450원을 넘은 후 계속 1,450원대에 머물러 있습니다.\n",
    "\n",
    "1,450원을 넘는 환율은 우리 증시 상승세를 이끌었던 외국인 투자자에겐 환차손 부담이 되고 있습니다.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a1af80b-7469-4fe0-894b-4cbb443c832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분리된 문장 개수: 20\n",
      "첫 번째 문장 명사: ['앵커', '지난주', '선', '아래', '코스피', '상승', '출발', '장', '초반', '선']\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "#노이즈 제거\n",
    "text = re.sub(\"r\\[.*?\\]\", \"\", example_txt) #example_txt에서 .*?\\와 같은 특수문자 제거\n",
    "text = re.sub(\"r\\w{2,4} 기자\", \"\", text) #??? 기자 삭제\n",
    "text = text.strip() #문자열의 양,끝에 노이즈를 제거하는\n",
    "\n",
    "#문장 분리\n",
    "sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "\n",
    "#명사 추출 함수\n",
    "def get_nouns(sentence):\n",
    "    nouns = okt.nouns(sentence)\n",
    "\n",
    "    return [n for n in nouns]\n",
    "\n",
    "print(f\"분리된 문장 개수: {len(sentences)}\")\n",
    "print(f\"첫 번째 문장 명사: {get_nouns(sentences[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ba79b5c-3771-4210-bb76-480d1bf150bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/nlp_study/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb7f0010-3589-4721-b085-94d3a4835b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 수치화\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#문장 리스트를 명사 꾸러미로 변환\n",
    "sent_nouns = [\" \".join(get_nouns(s)) for s in sentences]\n",
    "\n",
    "#TF-IDF 행렬 생성\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(sent_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c824ed14-76d5-4916-bda2-6090f52b5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 요약 수행\n",
    "import numpy as np\n",
    "\n",
    "#각 문장별 점수 합산\n",
    "user_scores = np.array(tfidf_matrix.sum(axis=1)).flatten()\n",
    "\n",
    "#점수가 높은 순으로 인덱스 정렬 점수 상위3개\n",
    "top_indices = user_scores.argsort()[-3:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8918f624-ca3b-46a0-ba8b-3f7b044ba0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사 3줄 요약\n",
      "1. 하나와 KB, iM 금융지주 등 은행주는 4% 이상 급등하는 등 강세를 보이고 있습니다.\n",
      "2. 지난주 금요일 뉴욕 증시가 혼조세로 마감했고 원-달러 환율이 오르고 있어서 하락 출발할 것이란 전망이 있었는데 현재까지 코스피는 선방하고 있습니다.\n",
      "3. 시장에선 미국 행정부의 셧다운 해제가 임박했다는 소식과 우리 정부의 배당소득 분리과세 완화 방침에 코스피가 반등한 것으로 보고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "#데이터 후 처리 및 정제\n",
    "\n",
    "#원래 문장 순서대로 다시 정렬(가독성 확보)\n",
    "final_indices = sorted(top_indices)\n",
    "\n",
    "#최종 요약문 결합\n",
    "summary = [sentences[i] for i in final_indices]\n",
    "\n",
    "print(\"뉴스 기사 3줄 요약\")\n",
    "for i, s in enumerate(summary):\n",
    "    print(f\"{i+1}. {s}.\")\n",
    "\n",
    "#정제 작업: 문장 끝에 마침표가 없다면 추가해주는 등의 마무리 \n",
    "final_summary = \". \".join(summary) + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb4f8fe6-3f7d-4854-95b2-1941859d9362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상승: 6회\n",
      "환율: 6회\n",
      "코스피: 5회\n",
      "출발: 5회\n",
      "달러: 5회\n",
      "보이: 4회\n",
      "현재: 4회\n",
      "외국인: 4회\n",
      "기자: 3회\n",
      "매수: 3회\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be5a1b-3a1b-4a5c-a754-702f3a126526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546c753-17cb-4435-9719-b6eef986be0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "025ff709-11de-4e8f-8e23-a7000a75ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e83625b0-5510-4ccd-a1c7-aede462dd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['상승', '환율', '코스피', '출발', '달러', '보이', '현재', '외국인', '기자', '매수'] [6, 6, 5, 5, 5, 4, 4, 4, 3, 3]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd85197-55ea-4b3b-87dc-a9fc85c2e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "#명사 추출\n",
    "nouns = okt.nouns(example_txt)\n",
    "print(len(nouns))\n",
    "#형용사 추출\n",
    "pos = okt.pos(example_txt)\n",
    "print(len(pos))\n",
    "#모든 형태소를 리스트로 추출\n",
    "morphs = okt.morphs(example_txt)\n",
    "print(len(morphs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
